{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"executionInfo":{"elapsed":28789,"status":"ok","timestamp":1751210008206,"user":{"displayName":"Santiago Piazza","userId":"15288552211194460355"},"user_tz":180},"id":"5spPlxfyuCgE","outputId":"aa2fb0b7-644d-4ba6-a7a9-3816b1a22479"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"executionInfo":{"elapsed":8653,"status":"ok","timestamp":1751210019226,"user":{"displayName":"Santiago Piazza","userId":"15288552211194460355"},"user_tz":180},"id":"cOisxEmatMRw","outputId":"211d448e-cbab-4c18-9d0f-2884409285e8"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 1)) (2.2.2)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 2)) (2.0.2)\n","Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 3)) (2.18.0)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 4)) (1.6.1)\n","Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 5)) (11.2.1)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->-r requirements.txt (line 1)) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->-r requirements.txt (line 1)) (2025.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->-r requirements.txt (line 1)) (2025.2)\n","Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow->-r requirements.txt (line 3)) (1.4.0)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow->-r requirements.txt (line 3)) (1.6.3)\n","Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow->-r requirements.txt (line 3)) (25.2.10)\n","Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow->-r requirements.txt (line 3)) (0.6.0)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow->-r requirements.txt (line 3)) (0.2.0)\n","Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow->-r requirements.txt (line 3)) (18.1.1)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow->-r requirements.txt (line 3)) (3.4.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow->-r requirements.txt (line 3)) (24.2)\n","Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow->-r requirements.txt (line 3)) (5.29.5)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow->-r requirements.txt (line 3)) (2.32.3)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow->-r requirements.txt (line 3)) (75.2.0)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow->-r requirements.txt (line 3)) (1.17.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow->-r requirements.txt (line 3)) (3.1.0)\n","Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow->-r requirements.txt (line 3)) (4.14.0)\n","Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow->-r requirements.txt (line 3)) (1.17.2)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow->-r requirements.txt (line 3)) (1.73.0)\n","Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow->-r requirements.txt (line 3)) (2.18.0)\n","Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow->-r requirements.txt (line 3)) (3.8.0)\n","Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow->-r requirements.txt (line 3)) (3.14.0)\n","Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow->-r requirements.txt (line 3)) (0.4.1)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow->-r requirements.txt (line 3)) (0.37.1)\n","Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->-r requirements.txt (line 4)) (1.15.3)\n","Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->-r requirements.txt (line 4)) (1.5.1)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->-r requirements.txt (line 4)) (3.6.0)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow->-r requirements.txt (line 3)) (0.45.1)\n","Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow->-r requirements.txt (line 3)) (13.9.4)\n","Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow->-r requirements.txt (line 3)) (0.1.0)\n","Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow->-r requirements.txt (line 3)) (0.16.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow->-r requirements.txt (line 3)) (3.4.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow->-r requirements.txt (line 3)) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow->-r requirements.txt (line 3)) (2.4.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow->-r requirements.txt (line 3)) (2025.6.15)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow->-r requirements.txt (line 3)) (3.8.2)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow->-r requirements.txt (line 3)) (0.7.2)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow->-r requirements.txt (line 3)) (3.1.3)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow->-r requirements.txt (line 3)) (3.0.2)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow->-r requirements.txt (line 3)) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow->-r requirements.txt (line 3)) (2.19.2)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow->-r requirements.txt (line 3)) (0.1.2)\n"]}],"source":["import os\n","os.chdir('/content/drive/MyDrive/TFI/') # Cambiar a la ruta donde están los datasets\n","!pip install -r requirements.txt"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"executionInfo":{"elapsed":10137,"status":"ok","timestamp":1751210033205,"user":{"displayName":"Santiago Piazza","userId":"15288552211194460355"},"user_tz":180},"id":"BYtgQAyo3b5X","outputId":"d40f8836-0f2e-428e-a41b-9c363e0eaa69"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["<module 'data_loader' from '/content/drive/MyDrive/TFI/data_loader.py'>"]},"metadata":{},"execution_count":3}],"source":["import config\n","import model\n","import evaluate\n","import data_loader\n","import importlib\n","\n","importlib.reload(config)\n","\n","importlib.reload(model)\n","\n","importlib.reload(evaluate)\n","importlib.reload(data_loader)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2066554,"status":"ok","timestamp":1751074982694,"user":{"displayName":"Santiago Piazza","userId":"15288552211194460355"},"user_tz":180},"id":"ro_bYZgBJEAh","outputId":"e23848cc-2714-4c0d-e4b4-7e6591390022"},"outputs":[{"name":"stdout","output_type":"stream","text":["Cargando y preprocesando datos...\n","Creando datasets...\n","Construyendo modelo...\n","Entrenando modelo...\n","Epoch 1/8\n","\u001b[1m6982/6982\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m292s\u001b[0m 16ms/step - auc: 0.7429 - loss: 0.4742 - val_auc: 0.7926 - val_loss: 0.5990\n","Epoch 2/8\n","\u001b[1m6982/6982\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m271s\u001b[0m 15ms/step - auc: 0.7905 - loss: 0.4418 - val_auc: 0.7771 - val_loss: 0.4915\n","Epoch 3/8\n","\u001b[1m6982/6982\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m274s\u001b[0m 15ms/step - auc: 0.8074 - loss: 0.4279 - val_auc: 0.8129 - val_loss: 0.4703\n","Epoch 4/8\n","\u001b[1m6982/6982\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m251s\u001b[0m 15ms/step - auc: 0.8169 - loss: 0.4181 - val_auc: 0.7895 - val_loss: 0.4878\n","Epoch 5/8\n","\u001b[1m6982/6982\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m247s\u001b[0m 15ms/step - auc: 0.8244 - loss: 0.4115 - val_auc: 0.8078 - val_loss: 0.4666\n","Epoch 6/8\n","\u001b[1m6982/6982\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m245s\u001b[0m 15ms/step - auc: 0.8285 - loss: 0.4070 - val_auc: 0.7626 - val_loss: 0.5419\n","Epoch 7/8\n","\u001b[1m6982/6982\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m242s\u001b[0m 15ms/step - auc: 0.8318 - loss: 0.4047 - val_auc: 0.8192 - val_loss: 0.4866\n","Epoch 8/8\n","\u001b[1m6982/6982\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m239s\u001b[0m 15ms/step - auc: 0.8355 - loss: 0.4013 - val_auc: 0.8326 - val_loss: 0.4918\n","\n","Evaluando modelo...\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 145ms/step\n","\n","Métricas del Modelo en el Conjunto de Validación:\n","\n","----- Atelectasis  (threshold = 0.341) -----\n","ROC AUC: 0.8347\n","Precisión: 0.6383\n","Recall:    0.6977\n","Puntuación F1: 0.6667\n","\n","----- Cardiomegaly  (threshold = 0.067) -----\n","ROC AUC: 0.8944\n","Precisión: 0.6667\n","Recall:    0.7368\n","Puntuación F1: 0.7000\n","\n","----- Consolidation  (threshold = 0.088) -----\n","ROC AUC: 0.8990\n","Precisión: 0.5714\n","Recall:    0.6667\n","Puntuación F1: 0.6154\n","\n","----- Edema  (threshold = 0.502) -----\n","ROC AUC: 0.8746\n","Precisión: 0.7143\n","Recall:    0.4545\n","Puntuación F1: 0.5556\n","\n","----- Pleural Effusion  (threshold = 0.327) -----\n","ROC AUC: 0.9060\n","Precisión: 0.8889\n","Recall:    0.5854\n","Puntuación F1: 0.7059\n"]}],"source":["from config import TRAIN_CSV, VALID_CSV, BATCH_SIZE, EPOCHS, COMPETITION_TASKS\n","from data_loader import load_and_preprocess_data, create_dataset\n","from model import build_model\n","from evaluate import evaluate_model\n","import tensorflow as tf\n","import importlib\n","importlib.reload(config)\n","\n","importlib.reload(model)\n","\n","importlib.reload(evaluate)\n","\n","def main():\n","    \"\"\"Función principal para ejecutar el pipeline de entrenamiento y evaluación.\"\"\"\n","    print(\"Cargando y preprocesando datos...\")\n","    train_df = load_and_preprocess_data(TRAIN_CSV)\n","    valid_df = load_and_preprocess_data(VALID_CSV)\n","\n","    # Para una ejecución de prueba más rápida, usemos una fracción menor de los datos.\n","    # Eliminar estas líneas para ejecutar en el conjunto de datos completo.\n","    train_df = train_df.sample(frac=0.50, random_state=42)\n","    valid_df = valid_df.sample(frac=0.50, random_state=42)\n","\n","    print(\"Creando datasets...\")\n","    train_dataset = create_dataset(train_df, BATCH_SIZE)\n","    # Crear un dataset de validación sin mezclar para la evaluación\n","    valid_dataset = create_dataset(valid_df, BATCH_SIZE, shuffle=False)\n","\n","    print(\"Construyendo modelo...\")\n","    model = build_model(len(COMPETITION_TASKS))\n","\n","    print(\"Entrenando modelo...\")\n","    model.fit(\n","      train_dataset,\n","      epochs=EPOCHS,\n","      validation_data=valid_dataset\n","    )\n","\n","    print(\"\\nEvaluando modelo...\")\n","    evaluate_model(model, valid_dataset, valid_df)\n","\n","if __name__ == '__main__':\n","    main()\n","\n"]},{"cell_type":"markdown","metadata":{"id":"LiVV0xxJf6KA"},"source":["# **Para encontrar los mejores thresolds**"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Itj9AnWudFSA","outputId":"847ee1c8-e5be-4454-b37c-a7b784100d6d"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/8\n"]}],"source":["from config import TRAIN_CSV, VALID_CSV, BATCH_SIZE, EPOCHS, COMPETITION_TASKS\n","from data_loader import load_and_preprocess_data, create_dataset\n","from model import build_model\n","from evaluate import evaluate_model\n","import tensorflow as tf\n","import importlib\n","importlib.reload(config)\n","\n","importlib.reload(model)\n","\n","importlib.reload(evaluate)\n","import numpy as np\n","from sklearn.metrics import precision_recall_curve\n","\n","train_df  = load_and_preprocess_data(TRAIN_CSV).sample(frac=0.50, random_state=42)\n","valid_df  = load_and_preprocess_data(VALID_CSV).sample(frac=0.50, random_state=42)\n","\n","train_ds  = create_dataset(train_df,  BATCH_SIZE)\n","valid_ds  = create_dataset(valid_df,  BATCH_SIZE, shuffle=False)\n","\n","net = build_model(len(COMPETITION_TASKS))\n","net.fit(train_ds, epochs=EPOCHS, validation_data=valid_ds)\n","\n","y_pred_probs = net.predict(valid_ds)\n","\n","best_thr = {}\n","print(\"Umbrales optimizados en validación (criterio: F1 máximo)\")\n","for i, task in enumerate(COMPETITION_TASKS):\n","    y_true = valid_df[task].values\n","    y_prob = y_pred_probs[:, i]\n","\n","    pr, rc, thr = precision_recall_curve(y_true, y_prob)\n","    f1 = 2 * pr * rc / (pr + rc + 1e-8)       # evita división por 0\n","    idx = np.argmax(f1)                       # índice del F1 máximo\n","    best_thr[task] = thr[idx]                 # guarda el umbral óptimo\n","\n","    print(f\"{task:15s}:  {thr[idx]:.3f}   (F1 = {f1[idx]:.3f})\")\n","\n","evaluate_model(net, valid_ds, valid_df)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":19,"status":"ok","timestamp":1751070251072,"user":{"displayName":"Santiago Piazza","userId":"15288552211194460355"},"user_tz":180},"id":"eXoPCJhF0dkZ","outputId":"0be45403-c503-449c-baee-a5f17b4d43ee"},"outputs":[{"name":"stdout","output_type":"stream","text":["8\n"]}],"source":["import config\n","import importlib\n","importlib.reload(config)\n","print(config.EPOCHS)"]},{"cell_type":"markdown","metadata":{"id":"-h90XuesSeO_"},"source":["# Sección nueva"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":19,"status":"ok","timestamp":1751072872514,"user":{"displayName":"Santiago Piazza","userId":"15288552211194460355"},"user_tz":180},"id":"GulR4IfqJEAi","outputId":"38719bf1-82e7-4553-a54d-de7108dc7d84"},"outputs":[{"name":"stdout","output_type":"stream","text":["Cardiomegaly  nuevo thr = 0.067  |  Prec=0.500  Rec=0.921\n"]}],"source":["from sklearn.metrics import precision_recall_curve\n","import numpy as np\n","\n","task = 'Cardiomegaly'\n","i    = COMPETITION_TASKS.index(task)\n","y_true = valid_df[task].values\n","y_prob = y_pred_probs[:, i]\n","\n","pr, rc, thr = precision_recall_curve(y_true, y_prob)\n","thr = np.append(thr, 1.0)                 # alinear longitudes\n","\n","target_prec = 0.50                        # mínimo deseado\n","mask = pr >= target_prec\n","\n","if mask.any():\n","    # elige el umbral con mayor recall dentro de Prec ≥ 0.50\n","    idx = np.argmax(rc[mask])\n","    new_thr = float(thr[mask][idx])\n","    new_prec, new_rec = pr[mask][idx], rc[mask][idx]\n","else:\n","    # nunca alcanza 0.50 → pon 0.99 y reconsidera entrenamiento\n","    new_thr, new_prec, new_rec = 0.99, pr[-1], rc[-1]\n","\n","print(f\"Cardiomegaly  nuevo thr = {new_thr:.3f}  |  Prec={new_prec:.3f}  Rec={new_rec:.3f}\")"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"A100","machine_shape":"hm","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.10"}},"nbformat":4,"nbformat_minor":0}